{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:05.591036Z",
     "start_time": "2024-06-15T22:27:03.680698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has access to the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# See TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f6f300feadf7c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:05.840382Z",
     "start_time": "2024-06-15T22:27:05.592162Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# RGB\n",
    "colors_rgb = {\n",
    "    0: (0x00, 0x00, 0x00),\n",
    "    1: (0x00, 0x74, 0xD9),\n",
    "    2: (0xFF, 0x41, 0x36),\n",
    "    3: (0x2E, 0xCC, 0x40),\n",
    "    4: (0xFF, 0xDC, 0x00),\n",
    "    5: (0xA0, 0xA0, 0xA0),\n",
    "    6: (0xF0, 0x12, 0xBE),\n",
    "    7: (0xFF, 0x85, 0x1B),\n",
    "    8: (0x7F, 0xDB, 0xFF),\n",
    "    9: (0x87, 0x0C, 0x25),\n",
    "}\n",
    "\n",
    "_float_colors = [tuple(c / 255 for c in col) for col in colors_rgb.values()]\n",
    "arc_cmap = ListedColormap(_float_colors)\n",
    "\n",
    "class ArcColors:\n",
    "    BLACK = 0\n",
    "    BLUE = 1\n",
    "    RED = 2\n",
    "    GREEN = 3\n",
    "    YELLOW = 4\n",
    "    GREY = 5\n",
    "    FUCHSIA = 6\n",
    "    ORANGE = 7\n",
    "    TEAL = 8\n",
    "    BROWN = 9\n",
    "\n",
    "def plot_grid(grid1: np.ndarray, grid2: np.ndarray = None):\n",
    "    \n",
    "    if grid2 is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.pcolormesh(\n",
    "            grid1,\n",
    "            cmap=arc_cmap,\n",
    "            rasterized=True,\n",
    "            vmin=0,\n",
    "            vmax=9,\n",
    "        )\n",
    "        ax.set_xticks(np.arange(0, grid1.shape[1], 1))\n",
    "        ax.set_yticks(np.arange(0, grid1.shape[0], 1))\n",
    "        ax.grid()\n",
    "        ax.set_aspect(1)\n",
    "        ax.invert_yaxis()\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "    axs[0].pcolormesh(\n",
    "        grid1,\n",
    "        cmap=arc_cmap,\n",
    "        rasterized=True,\n",
    "        vmin=0,\n",
    "        vmax=9,\n",
    "    )\n",
    "    axs[0].set_xticks(np.arange(0, grid1.shape[1], 1))\n",
    "    axs[0].set_yticks(np.arange(0, grid1.shape[0], 1))\n",
    "    axs[0].grid()\n",
    "    axs[0].set_aspect(1)\n",
    "    axs[0].invert_yaxis()\n",
    "\n",
    "    axs[1].pcolormesh(\n",
    "        grid2,\n",
    "        cmap=arc_cmap,\n",
    "        rasterized=True,\n",
    "        vmin=0,\n",
    "        vmax=9,\n",
    "    )\n",
    "    axs[1].set_xticks(np.arange(0, grid2.shape[1], 1))\n",
    "    axs[1].set_yticks(np.arange(0, grid2.shape[0], 1))\n",
    "    axs[1].grid()\n",
    "    axs[1].set_aspect(1)\n",
    "    axs[1].invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7520c984acfac491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:06.186200Z",
     "start_time": "2024-06-15T22:27:05.841197Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a9ce39331241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:06.191228Z",
     "start_time": "2024-06-15T22:27:06.187633Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Load the data from the data/train directory containing the json files\n",
    "# files are named {random_number}.json so you need to list all the files in the directory and then load the data from each file\n",
    "training_data_dir = \"../data/training\"\n",
    "evaluating_data_dir = \"../data/evaluation\"\n",
    "\n",
    "# List of JSON file paths\n",
    "training_file_paths = [os.path.join(training_data_dir, f) for f in os.listdir(training_data_dir)]\n",
    "evaluating_file_paths = [os.path.join(evaluating_data_dir, f) for f in os.listdir(evaluating_data_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f202f67e8f68530e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:06.195589Z",
     "start_time": "2024-06-15T22:27:06.191968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/training/a85d4709.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff97a4868066ba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:06.366564Z",
     "start_time": "2024-06-15T22:27:06.197159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to load data from multiple files\n",
    "\n",
    "def load_data(file_paths):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for file_path in file_paths:\n",
    "        rules_input = []\n",
    "        test_input = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for item in data['train']:\n",
    "                rules_input.append([\n",
    "                    np.array(item['input'], dtype=np.int64),\n",
    "                    np.array(item['output'], dtype=np.int64)\n",
    "                ])\n",
    "            for item in data['test']:\n",
    "                test_input.append([\n",
    "                    np.array(item['input'], dtype=np.int64),\n",
    "                    np.array(item['output'], dtype=np.int64)\n",
    "                ])\n",
    "        train_data.append(rules_input)\n",
    "        test_data.append(test_input)\n",
    "    return train_data, test_data\n",
    "\n",
    "# Load data from multiple files\n",
    "training_train_data, training_test_data = load_data(training_file_paths)\n",
    "evaluating_train_data, evaluating_test_data = load_data(evaluating_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45d4c25bba119e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e24f2cb27d96ca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:06.374743Z",
     "start_time": "2024-06-15T22:27:06.367186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.55555556, 0.55555556,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.55555556, 0.55555556,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.55555556, 0.55555556, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.55555556, 0.55555556, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from skimage.transform import resize\n",
    "\n",
    "def normalize_data(data):\n",
    "    return data / 9.0\n",
    "\n",
    "def denormalize_data(data):\n",
    "    return data * 9.0\n",
    "\n",
    "\n",
    "# test expand_matrix\n",
    "test_matrix = training_train_data[0][0][0]\n",
    "\n",
    "def expand_squared_matrix(matrix, size):\n",
    "    max_size = 32\n",
    "    current_size = matrix.shape[0]\n",
    "    if current_size == max_size:\n",
    "        return normalize_data(matrix)\n",
    "    ratio = max_size // current_size\n",
    "    divisible = ratio * current_size == max_size\n",
    "    if divisible is True:\n",
    "       return normalize_data(matrix.repeat(ratio, axis=0).repeat(ratio, axis=1))\n",
    "\n",
    "    ## if the size is not divisible by 32\n",
    "    ## we need to add padding and center the reiszed image\n",
    "    floor_ratio = np.floor(ratio)\n",
    "    resized_matrix = matrix.repeat(floor_ratio, axis=0).repeat(floor_ratio, axis=1)\n",
    "    pad_size = max_size - resized_matrix.shape[0]\n",
    "    padded_matrix = np.full(size, 0)\n",
    "    padded_matrix[pad_size//2:pad_size//2+resized_matrix.shape[0], pad_size//2:pad_size//2+resized_matrix.shape[1]] = resized_matrix\n",
    "    return normalize_data(padded_matrix)\n",
    "\n",
    "\n",
    "def expand_rectangular_matrix(matrix, size):\n",
    "    max_size = 32\n",
    "    current_size = matrix.shape[0]\n",
    "    current_width = matrix.shape[1]\n",
    "    if current_size == max_size and current_width == max_size:\n",
    "        return normalize_data(matrix)\n",
    "    ratio = max_size // current_size\n",
    "    ratio_width = max_size // current_width\n",
    "    divisible = ratio * current_size == max_size and ratio_width * current_width == max_size\n",
    "    if divisible is True:\n",
    "       return normalize_data(matrix.repeat(ratio, axis=0).repeat(ratio_width, axis=1))\n",
    "\n",
    "    ## if the size is not divisible by 32\n",
    "    ## we need to add padding and center the reiszed image\n",
    "    floor_ratio = np.floor(ratio)\n",
    "    floor_ratio_width = np.floor(ratio_width)\n",
    "    resized_matrix = matrix.repeat(floor_ratio, axis=0).repeat(floor_ratio_width, axis=1)\n",
    "    pad_size = max_size - resized_matrix.shape[0]\n",
    "    pad_size_width = max_size - resized_matrix.shape[1]\n",
    "    padded_matrix = np.full(size, 0)\n",
    "    padded_matrix[pad_size//2:pad_size//2+resized_matrix.shape[0], pad_size_width//2:pad_size_width//2+resized_matrix.shape[1]] = resized_matrix\n",
    "    return normalize_data(padded_matrix)\n",
    "\n",
    "def expand_matrix(matrix, size):\n",
    "    if matrix.shape[0] == matrix.shape[1]:\n",
    "        return expand_squared_matrix(matrix, size)\n",
    "    return expand_rectangular_matrix(matrix, size)\n",
    "\n",
    "expanded_matrix = expand_matrix(test_matrix, (32, 32))\n",
    "expanded_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16a58db4424455d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:12.056399Z",
     "start_time": "2024-06-15T22:27:06.375981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 00:27:06.436490: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-16 00:27:06.436928: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2400, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "## now we created input a, b, c and output in a array\n",
    "def extract_data(train, test, max_pairs=5):\n",
    "    inputs_a = []\n",
    "    input_c = []\n",
    "    output = []\n",
    "    for inputs in train:\n",
    "        matrix = []\n",
    "        for i, element in enumerate(inputs):\n",
    "            if i == max_pairs:\n",
    "                break\n",
    "            expanded_0 = expand_matrix(element[0], (32, 32))\n",
    "            reshaped_0 = np.reshape(expanded_0, (1, 32*32))\n",
    "            matrix.append(reshaped_0)\n",
    "            expanded_1 = expand_matrix(element[1], (32, 32))\n",
    "            reshaped_1 = np.reshape(expanded_1, (1, 32*32))\n",
    "            matrix.append(reshaped_1)\n",
    "        ## generate a matrix of 64x(5 max pairs)\n",
    "        if len(matrix) < max_pairs*2:\n",
    "            for i in range(max_pairs*2 - len(matrix)):\n",
    "                matrix.append(np.zeros((1, 32*32)))\n",
    "        inputs_a.append(np.array(matrix))\n",
    "\n",
    "    for inputs in test:\n",
    "        first_element = inputs[0]\n",
    "        input_c.append(first_element[0])\n",
    "        output.append(first_element[1])\n",
    "\n",
    "\n",
    "    reshaped_input_a = [tf.reshape(tf.convert_to_tensor(x, np.int64), ) for x in inputs_a]\n",
    "    reshaped_input_c = [tf.reshape(expand_matrix(x, (32, 32)), (1, 32*32)) for x in input_c]\n",
    "    reshaped_output = [tf.reshape(expand_matrix(x, (32, 32)), (1, 32*32)) for x in output]\n",
    "    A = tf.data.Dataset.from_tensor_slices(reshaped_input_a)\n",
    "    C = tf.data.Dataset.from_tensor_slices(reshaped_input_c)\n",
    "    Abc = tf.data.Dataset.zip((A,C)).map(lambda a,c: {'a_input': a, 'c_input': c})\n",
    "    z_true = tf.data.Dataset.from_tensor_slices(reshaped_output)\n",
    "    return tf.data.Dataset.zip((Abc, z_true))\n",
    "\n",
    "def generate_rotate_matrix(matrix_list):\n",
    "    new_matrix_list = []\n",
    "    for matrix in matrix_list:\n",
    "        for i in range(4):\n",
    "            new_matrix_list.append(np.rot90(matrix, i+1))\n",
    "    return new_matrix_list\n",
    "\n",
    "def generate_flip_matrix(matrix_list):\n",
    "    new_matrix_list = []\n",
    "    for matrix in matrix_list:\n",
    "        new_matrix_list.append(np.flip(matrix, 0))\n",
    "        new_matrix_list.append(np.flip(matrix, 1))\n",
    "    return new_matrix_list\n",
    "\n",
    "def generate_all_transformations(matrix):\n",
    "    rotated_matrix = generate_rotate_matrix(matrix)\n",
    "    flipped_matrix = generate_flip_matrix(matrix)\n",
    "    return rotated_matrix + flipped_matrix\n",
    "\n",
    "def extract_data_V1(train, test, max_pairs=5):\n",
    "    inputs_a = []\n",
    "    input_c = []\n",
    "    output = []\n",
    "\n",
    "    for inputs in train:\n",
    "        matrix = []\n",
    "        for i, element in enumerate(inputs):\n",
    "            if i == max_pairs:\n",
    "                break\n",
    "            expanded_0 = expand_matrix(element[0], (32, 32))\n",
    "            matrix.append(expanded_0)\n",
    "            expanded_1 = expand_matrix(element[1], (32, 32))\n",
    "            matrix.append(expanded_1)\n",
    "        ## generate a matrix of 64x(5 max pairs)\n",
    "        if len(matrix) < max_pairs*2:\n",
    "            for i in range(max_pairs*2 - len(matrix)):\n",
    "                matrix.append(np.zeros((32,32)))\n",
    "        ## transpose the matrix to have the correct shape\n",
    "        inputs_a.append(np.transpose(np.array(matrix), (1, 2, 0)))\n",
    "\n",
    "    for inputs in test:\n",
    "        first_element = inputs[0]\n",
    "        input_c.append(expand_matrix(first_element[0], (32, 32)))\n",
    "        output.append(expand_matrix(first_element[1], (32, 32)))\n",
    "\n",
    "    synth_input_a = generate_all_transformations(inputs_a)\n",
    "    synth_input_c = generate_all_transformations(input_c)\n",
    "    synth_output = generate_all_transformations(output)\n",
    "\n",
    "    reshaped_input_a = [tf.convert_to_tensor(np.expand_dims(x, axis=0), dtype=tf.float16) for x in synth_input_a]\n",
    "    reshaped_input_c = [tf.convert_to_tensor(np.expand_dims(x, axis=0), dtype=tf.float16) for x in synth_input_c]\n",
    "    reshaped_output = [tf.convert_to_tensor(np.expand_dims(x, axis=0), dtype=tf.float16) for x in synth_output]\n",
    "    A = tf.data.Dataset.from_tensor_slices(reshaped_input_a)\n",
    "    C = tf.data.Dataset.from_tensor_slices(reshaped_input_c)\n",
    "    Abc = tf.data.Dataset.zip((A,C)).map(lambda a,c: {'a_input': a, 'c_input': c})\n",
    "    z_true = tf.data.Dataset.from_tensor_slices(reshaped_output)\n",
    "    return tf.data.Dataset.zip((Abc, z_true))\n",
    "\n",
    "train_data = extract_data_V1(training_train_data, training_test_data)\n",
    "eval_data = extract_data_V1(evaluating_train_data, evaluating_test_data)\n",
    "\n",
    "### print the size of the data\n",
    "print(train_data.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7abc516843d49891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:12.141903Z",
     "start_time": "2024-06-15T22:27:12.057261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30, 30, 32)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the data A\n",
    "\n",
    "input_layer = tf.keras.layers.Input(shape=(32, 32, 10))\n",
    "conv_layer = tf.keras.layers.Conv2D(32, 3, activation='relu')(input_layer)\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=conv_layer)\n",
    "\n",
    "# Now you can use this tensor as input to the model\n",
    "output = model(train_data.take(1).as_numpy_iterator().next()[0]['a_input'])\n",
    "print(output.shape)  # This should work without error\n",
    "\n",
    "#\n",
    "# input_layer = tf.keras.layers.Input(shape=(32, 32, 1))\n",
    "# conv_layer = tf.keras.layers.Conv2D(32, 3, activation='relu')(input_layer)\n",
    "# model = tf.keras.Model(inputs=input_layer, outputs=conv_layer)\n",
    "#\n",
    "# # Now you can use this tensor as input to the model\n",
    "# output = model(train_data.take(1).as_numpy_iterator().next()[0]['c_input'])\n",
    "# print(output.shape)  # This should work without error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e2999a395109da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:12.152428Z",
     "start_time": "2024-06-15T22:27:12.143949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def display_output(output_1, output_2=None):\n",
    "    output_1 = output_1.reshape(32,32)\n",
    "    output_1 = denormalize_data(output_1)\n",
    "    \n",
    "    if output_2 is None:\n",
    "        plot_grid(output_1)\n",
    "        return\n",
    "    output_2 = denormalize_data(output_2)\n",
    "    output_2 = output_2.reshape(32,32)\n",
    "    plot_grid(output_1, output_2)\n",
    "\n",
    "train_data.take(1).as_numpy_iterator().next()[0]['a_input'].shape\n",
    "#\n",
    "#display_output(train_data.take(1).as_numpy_iterator().next()[0]['a_input'], train_data.take(1).as_numpy_iterator().next()[0]['b_input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a964ef6911f582",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de7bbd1b0f2b5238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:12.353463Z",
     "start_time": "2024-06-15T22:27:12.153284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " a_input (InputLayer)           [(None, 32, 32, 10)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " masking (Masking)              (None, 32, 32, 10)   0           ['a_input[0][0]']                \n",
      "                                                                                                  \n",
      " c_input (InputLayer)           [(None, 32, 32, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 32)   2912        ['masking[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 32)   320         ['c_input[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 32)  128         ['conv2d_1[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 32)   9248        ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 32)   9248        ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 16, 16, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 64)   0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 64)   36928       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 64)   36928       ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 128)    73856       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 128)    147584      ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 16, 16, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 64)   73792       ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 64)   36928       ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 64)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 32)   18464       ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 32, 32, 32)  128         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 32)   9248        ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 32, 32)  128         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 1)    289         ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 458,561\n",
      "Trainable params: 457,153\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_model_V0(max_pairs=5):\n",
    "    a_input = keras.layers.Input(shape=(32*32*10), name='a_input')\n",
    "    x = keras.layers.Flatten()(a_input)\n",
    "    x = keras.layers.Dense(32*32)(x)  # Removed input_dim parameter\n",
    "\n",
    "    c_input = keras.layers.Input(shape=(32*32), name='c_input')\n",
    "    c = keras.layers.Flatten()(c_input)\n",
    "    c = keras.layers.Dense(32*32)(c)\n",
    "\n",
    "    z = keras.layers.concatenate(axis=1,inputs=[x, c])\n",
    "    z = keras.layers.Dense(32*32, activation='relu')(z)\n",
    "\n",
    "    model = keras.models.Model(inputs=[a_input, c_input], outputs=z)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_v1(max_pairs=5):\n",
    "    # First input branch\n",
    "    input1 = Input(shape=(32, 32, 10), name='a_input')  # 32x32 images with 10 channels\n",
    "    x = layers.Masking(mask_value=0.0)(input1)\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "    # Second input branch\n",
    "    input2 = Input(shape=(32, 32, 1), name='c_input')  # 32x32 images with 1 channel\n",
    "    y = layers.Conv2D(32, 3, strides=1, padding=\"same\", activation=\"relu\")(input2)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.MaxPooling2D(2)(y)\n",
    "\n",
    "    # Concatenate the two branches\n",
    "    concatenated = layers.concatenate([x, y])\n",
    "\n",
    "    # Additional layers for better learning\n",
    "    z = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(concatenated)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(z)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.MaxPooling2D(2)(z)\n",
    "\n",
    "    z = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(z)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(z)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "\n",
    "    z = layers.UpSampling2D(2)(z)\n",
    "    z = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(z)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(z)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.UpSampling2D(2)(z)\n",
    "    z = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(z)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(z)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Conv2D(1, 3, padding=\"same\", activation=\"sigmoid\")(z)  # Output shape: (32, 32, 1)\n",
    "\n",
    "    model = Model(inputs=[input1, input2], outputs=z)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model_v1()\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "418e21363732835f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_data_for_transformer(train, test, max_pairs=5):\n",
    "    pairs = []\n",
    "    # print(len(train[0]))\n",
    "    for i, element in enumerate(train):\n",
    "        if i == max_pairs:\n",
    "            break\n",
    "        expanded_0 = expand_matrix(element[0], (32, 32))\n",
    "        expanded_1 = expand_matrix(element[1], (32, 32))\n",
    "        pairs.append(expanded_0)\n",
    "        pairs.append(expanded_1)\n",
    "        # ## generate a matrix of 64x(5 max pairs)\n",
    "    # if len(train)*2 < max_pairs*2:\n",
    "    #     for i in range(max_pairs*2 - len(train) * 2):\n",
    "    #         pairs.append(np.zeros((32,32)))\n",
    "\n",
    "    # pairs.append(np.zeros((32,32)))\n",
    "    # pairs.append(np.zeros((32,32)))\n",
    "    # pairs.append(np.zeros((32,32)))\n",
    "\n",
    "    final_test = expand_matrix(test[0][0], (32, 32))\n",
    "    attended_output = expand_matrix(test[0][1], (32, 32))\n",
    "    return pairs, final_test, attended_output\n",
    "\n",
    "def extract_batch (data, test):\n",
    "    batches = []\n",
    "    for i in range(0, len(data)):\n",
    "        extracted = extract_data_for_transformer(data[i], test[i])\n",
    "        batches.append(extracted)\n",
    "        break\n",
    "        # for j in range(3):\n",
    "        #     rotated = [[np.rot90(x, j+1) for x in extracted[0]], np.rot90(extracted[1], j+1), np.rot90(extracted[2], j+1)]\n",
    "        #     batches.append(rotated)\n",
    "        #     batches.append([[np.flip(x, 0) for x in rotated[0]], np.flip(rotated[1], 0), np.flip(rotated[2], 0)])\n",
    "        # batches.append([[np.flip(x, 1) for x in extracted[0]], np.flip(extracted[1], 1), np.flip(extracted[2], 1)])\n",
    "\n",
    "    # ## data augmentation by rotating the matrix by 90, 180, 270 and fliping the matrix\n",
    "    # for data in batches:\n",
    "    #     _pairs = data[0]\n",
    "    #     _final_test = data[1]\n",
    "    #     _attended_output = data[2]\n",
    "    #     for i in range(3):\n",
    "    #         batches.append([[np.rot90(x, i+1) for x in _pairs], np.rot90(_final_test, i+1), np.rot90(_attended_output, i+1)])\n",
    "    #     batches.append([[np.flip(x, 1) for x in _pairs], np.flip(_final_test, 1), np.flip(_attended_output, 1)])\n",
    "\n",
    "    return batches\n",
    "\n",
    "train_data = extract_batch(training_train_data, training_test_data)\n",
    "eval_data = extract_batch(evaluating_train_data, evaluating_test_data)\n",
    "\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43e0ac50f7e7e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "#     # Normalization and Self-Attention\n",
    "#     x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "#     x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "#     x = layers.Dropout(dropout)(x)\n",
    "#     res = x + inputs  # Residual connection\n",
    "# \n",
    "#     # Feed Forward Part\n",
    "#     x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "#     x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation='relu')(x)\n",
    "#     x = layers.Dropout(dropout)(x)\n",
    "#     x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "#     return x + res  # Residual connection\n",
    "# \n",
    "# def positional_encoding(max_len, depth):\n",
    "#     positions = np.arange(max_len)[:, np.newaxis]\n",
    "#     depths = np.arange(depth)[np.newaxis, :]\n",
    "#     angle_rates = 1 / np.power(10000, (2 * (depths // 2)) / np.float32(depth))\n",
    "#     angle_rads = positions * angle_rates\n",
    "# \n",
    "#     # Apply the sin function to even indices in the array; 2i\n",
    "#     angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "# \n",
    "#     # Apply the cos function to odd indices in the array; 2i+1\n",
    "#     angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "# \n",
    "#     pos_encoding = angle_rads[np.newaxis, ...]\n",
    "#     return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs  # Residual connection\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res  # Residual connection\n",
    "\n",
    "def positional_encoding(max_len, depth):\n",
    "    positions = np.arange(max_len)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :]\n",
    "    angle_rates = 1 / np.power(10000, (2 * (depths // 2)) / np.float32(depth))\n",
    "    angle_rads = positions * angle_rates\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44807a7b53438f0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:12.777880Z",
     "start_time": "2024-06-15T22:27:12.366662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None, 32, 3  0           []                               \n",
      "                                2, 1)]                                                            \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1024, 1)      0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1024, 1)      0           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 1024, 0)     0           ['reshape[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 1024, 0)     0           ['tf.__operators__.add[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 1024, 0)     768         ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024, 0)      0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 1024, 0)      0           ['dropout[0][0]',                \n",
      "                                                                  'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 1024, 0)     0           ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024, 128)    128         ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024, 128)    0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024, 0)      0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 1024, 0)      0           ['dense_1[0][0]',                \n",
      "                                                                  'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 1024, 0)     0           ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 1024, 0)     768         ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1024, 0)      0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 1024, 0)      0           ['dropout_2[0][0]',              \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 1024, 0)     0           ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024, 128)    128         ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 1024, 128)    0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1024, 0)      0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1024, 0)      0           ['dense_3[0][0]',                \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 32, 32, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 1024, 0)     0           ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1024, 1)      0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 1024, 0)     0           ['layer_normalization_4[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 1024, 0)     0           ['reshape_1[0][0]']              \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 1024, 0)     768         ['layer_normalization_5[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 1024, 0)     0           ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 1024, 0)      0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 1024, 0)     768         ['layer_normalization_9[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 1024, 0)      0           ['dropout_4[0][0]',              \n",
      "                                                                  'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 1024, 0)      0           ['multi_head_attention_4[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 1024, 0)     0           ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 1024, 0)      0           ['dropout_8[0][0]',              \n",
      "                                                                  'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1024, 128)    128         ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 1024, 0)     0           ['add_8[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 1024, 128)    0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1024, 128)    128         ['layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1024, 0)      0           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 1024, 128)    0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 1024, 0)      0           ['dense_5[0][0]',                \n",
      "                                                                  'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1024, 0)      0           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 1024, 0)     0           ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 1024, 0)      0           ['dense_9[0][0]',                \n",
      "                                                                  'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 1024, 0)     768         ['layer_normalization_7[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 1024, 0)     0           ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 1024, 0)      0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 1024, 0)     768         ['layer_normalization_11[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 1024, 0)      0           ['dropout_6[0][0]',              \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 1024, 0)      0           ['multi_head_attention_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 1024, 0)     0           ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 1024, 0)      0           ['dropout_10[0][0]',             \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1024, 128)    128         ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 1024, 0)     0           ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 1024, 128)    0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1024, 128)    128         ['layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1024, 0)      0           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 1024, 128)    0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 1024, 0)      0           ['dense_7[0][0]',                \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1024, 0)      0           ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 1024, 0)      0           ['dense_11[0][0]',               \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (3,)                0           ['add_7[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 0)            0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOpLamb  (3,)                0           ['add_7[0][0]']                  \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 0)            0           ['reshape_2[0][0]',              \n",
      "                                                                  'tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  ()                  0           ['tf.compat.v1.shape_1[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (0, 1024, 1024)      0           ['lambda_1[0][0]',               \n",
      "                                                                  'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 1024, 0)      0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (0, 1024, 1024)      0           ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (0, 1024, 1024)      0           ['lambda_3[0][0]',               \n",
      "                                                                  'lambda_4[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (0, 1024, 1024)     2048        ['concatenate_1[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (0, 1024, 1024)     2048        ['layer_normalization_13[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (0, 1024, 1024)     1050368     ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (0, 1024, 1024)      0           ['multi_head_attention_6[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (0, 1024, 1024)      0           ['dropout_12[0][0]',             \n",
      "                                                                  'layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (0, 1024, 1024)     2048        ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (0, 1024, 128)       131200      ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (0, 1024, 128)       0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (0, 1024, 1024)      132096      ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (0, 1024, 1024)      0           ['dense_13[0][0]',               \n",
      "                                                                  'layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (0, 1024, 1024)     2048        ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (0, 1024, 1024)     1050368     ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (0, 1024, 1024)      0           ['multi_head_attention_7[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (0, 1024, 1024)      0           ['dropout_14[0][0]',             \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (0, 1024, 1024)     2048        ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (0, 1024, 128)       131200      ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (0, 1024, 128)       0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (0, 1024, 1024)      132096      ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (0, 1024, 1024)      0           ['dense_15[0][0]',               \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (0, 1024, 1024)      1049600     ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (0, 32, 32, 1)       0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (0, 32, 32, 32)      320         ['lambda_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (0, 32, 32, 32)      9248        ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (0, 32, 32, 1)       289         ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,702,401\n",
      "Trainable params: 3,702,401\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth // 2\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth\n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
    "    pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.1):\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Add()([x, inputs])\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.Dense(ff_dim, activation=tf.nn.gelu)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(inputs.shape[-1])(x)\n",
    "    x = layers.Add()([x, inputs])\n",
    "    return x\n",
    "\n",
    "def create_transformer_model(input_shape):\n",
    "    input_layer = Input(shape=(None, input_shape[0], input_shape[1], input_shape[2]))\n",
    "    pos_encoding = positional_encoding(input_shape[0] * input_shape[1], input_shape[2])\n",
    "\n",
    "    def process_pair(input_tensor):\n",
    "        x = layers.Reshape((input_shape[0] * input_shape[1], input_shape[2]))(input_tensor)\n",
    "        x = x + pos_encoding\n",
    "        for _ in range(2):\n",
    "            x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "        return x\n",
    "\n",
    "    input_pairs = layers.Lambda(lambda x: tf.reshape(x, (-1, input_shape[0] * input_shape[1], input_shape[2])))(input_layer)\n",
    "    processed_pairs = process_pair(input_pairs)\n",
    "    \n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(processed_pairs)\n",
    "    for _ in range(2):\n",
    "        x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "\n",
    "    final_input = Input(shape=input_shape)\n",
    "    flattened_final_input = layers.Reshape((input_shape[0] * input_shape[1], input_shape[2]))(final_input)\n",
    "    x_final = flattened_final_input + pos_encoding\n",
    "\n",
    "    for _ in range(2):\n",
    "        x_final = transformer_encoder(x_final, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "\n",
    "    flattened_x_final = layers.Reshape((-1,))(x_final)\n",
    "\n",
    "    def repeat_vector(args):\n",
    "        x, rep = args\n",
    "        return tf.repeat(x, repeats=rep, axis=1)\n",
    "\n",
    "    expanded_final_input = layers.Lambda(repeat_vector)([flattened_x_final, tf.shape(x)[1]])\n",
    "\n",
    "    def reshape_combined(args):\n",
    "        x, combined_shape = args\n",
    "        return tf.reshape(x, (-1, combined_shape, input_shape[0] * input_shape[1] * input_shape[2]))\n",
    "\n",
    "    expanded_final_input = layers.Lambda(reshape_combined)([expanded_final_input, tf.shape(x)[1]])\n",
    "\n",
    "    def flatten_combined_pairs(x):\n",
    "        shape = tf.shape(x)\n",
    "        return tf.reshape(x, (-1, shape[1], shape[2]))\n",
    "\n",
    "    combined_pairs_flat = layers.Lambda(flatten_combined_pairs)(x)\n",
    "    expanded_final_input_flat = layers.Lambda(flatten_combined_pairs)(expanded_final_input)\n",
    "\n",
    "    x_combined = layers.Concatenate(axis=-1)([combined_pairs_flat, expanded_final_input_flat])\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x_combined)\n",
    "    for _ in range(2):\n",
    "        x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "\n",
    "    x = layers.Dense(input_shape[0] * input_shape[1] * input_shape[2])(x)\n",
    "    def dynamic_reshape(tensor, shape):\n",
    "        return tf.reshape(tensor, shape)\n",
    "\n",
    "    output_shape = (-1, input_shape[0], input_shape[1], input_shape[2])\n",
    "    x = layers.Lambda(dynamic_reshape, arguments={'shape': output_shape})(x)\n",
    "\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(input_shape[2], 3, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = models.Model(inputs=[input_layer, final_input], outputs=x)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = (32, 32, 1)\n",
    "model = create_transformer_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# create_transformer_model((32, 32, 1))\n",
    "\n",
    "# def create_transformer_model(input_shape):\n",
    "#     inputs = []\n",
    "#     encoded_pairs = []\n",
    "# \n",
    "#     for _ in range(num_pairs):\n",
    "#         input_pattern = Input(shape=input_shape)\n",
    "#         output_pattern = Input(shape=input_shape)\n",
    "#         inputs.append(input_pattern)\n",
    "#         inputs.append(output_pattern)\n",
    "# \n",
    "#         # Flatten the input to 3D for positional encoding and Transformer layers\n",
    "#         flattened_input = layers.Reshape((input_shape[0] * input_shape[1], input_shape[2]))(input_pattern)\n",
    "#         flattened_output = layers.Reshape((input_shape[0] * input_shape[1], input_shape[2]))(output_pattern)\n",
    "# \n",
    "#         # Positional Encoding\n",
    "#         pos_encoding = positional_encoding(input_shape[0] * input_shape[1], input_shape[2])\n",
    "#         x_in = flattened_input + pos_encoding\n",
    "#         x_out = flattened_output + pos_encoding\n",
    "# \n",
    "#         # Transformer Encoder Layer\n",
    "#         for _ in range(2):  # Fewer layers for individual encoding\n",
    "#             x_in = transformer_encoder(x_in, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "#             x_out = transformer_encoder(x_out, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "# \n",
    "#         combined = layers.Concatenate(axis=2)([x_in, x_out])  # Concatenate along the feature dimension\n",
    "#         encoded_pairs.append(combined)\n",
    "# \n",
    "#     # Combine all encoded pairs\n",
    "#     combined_pairs = layers.Concatenate(axis=1)(encoded_pairs)\n",
    "# \n",
    "#     # Process the combined representation\n",
    "#     x = layers.LayerNormalization(epsilon=1e-6)(combined_pairs)\n",
    "#     for _ in range(2):  # Additional processing with more Transformer layers\n",
    "#         x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "# \n",
    "#     # Input for the final pattern\n",
    "#     final_input = Input(shape=input_shape)\n",
    "#     inputs.append(final_input)\n",
    "# \n",
    "#     flattened_final_input = layers.Reshape((input_shape[0] * input_shape[1], input_shape[2]))(final_input)\n",
    "#     x_final = flattened_final_input + pos_encoding\n",
    "# \n",
    "#     # Transformer Encoder Layer for the final input\n",
    "#     for _ in range(2):\n",
    "#         x_final = transformer_encoder(x_final, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "# \n",
    "#     # Flatten x_final to 2D\n",
    "#     flattened_x_final = layers.Reshape((-1,))(x_final)\n",
    "# \n",
    "#     # Expand the final input tensor to match the combined_pairs tensor along the sequence dimension\n",
    "#     def repeat_vector(args):\n",
    "#         x, rep = args\n",
    "#         return tf.repeat(x, repeats=rep, axis=1)\n",
    "# \n",
    "#     expanded_final_input = layers.Lambda(repeat_vector)([flattened_x_final, tf.shape(combined_pairs)[1]])\n",
    "# \n",
    "#     # Reshape back to 3D\n",
    "#     def reshape_combined(args):\n",
    "#         x, combined_shape = args\n",
    "#         return tf.reshape(x, (-1, combined_shape, input_shape[0] * input_shape[1] * input_shape[2]))\n",
    "# \n",
    "#     expanded_final_input = layers.Lambda(reshape_combined)([expanded_final_input, tf.shape(combined_pairs)[1]])\n",
    "# \n",
    "#     # Ensure shapes match for concatenation\n",
    "#     def flatten_combined_pairs(x):\n",
    "#         shape = tf.shape(x)\n",
    "#         return tf.reshape(x, (-1, shape[1], shape[2]))\n",
    "# \n",
    "#     combined_pairs_flat = layers.Lambda(flatten_combined_pairs)(combined_pairs)\n",
    "#     expanded_final_input_flat = layers.Lambda(flatten_combined_pairs)(expanded_final_input)\n",
    "# \n",
    "#     # Concatenate the processed combined_pairs and expanded_final_input\n",
    "#     x_combined = layers.Concatenate(axis=-1)([combined_pairs_flat, expanded_final_input_flat])\n",
    "# \n",
    "#     # Process the combined representation for the final prediction\n",
    "#     x = layers.LayerNormalization(epsilon=1e-6)(x_combined)\n",
    "#     for _ in range(2):  # Additional processing with more Transformer layers\n",
    "#         x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "# \n",
    "#     # Reshape to the correct output shape\n",
    "#     x = layers.Dense(input_shape[0] * input_shape[1] * input_shape[2])(x)\n",
    "#     def dynamic_reshape(tensor, shape):\n",
    "#         return tf.reshape(tensor, shape)\n",
    "# \n",
    "#     output_shape = (-1, input_shape[0], input_shape[1], input_shape[2])\n",
    "#     x = layers.Lambda(dynamic_reshape, arguments={'shape': output_shape})(x)\n",
    "# \n",
    "# \n",
    "#     x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "#     x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "#     x = layers.Conv2D(input_shape[2], 3, padding=\"same\", activation=\"sigmoid\")(x)  # Ensuring output shape matches input shape\n",
    "# \n",
    "#     model = models.Model(inputs=inputs, outputs=x)\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "\n",
    "# Create the Transformer model\n",
    "input_shape = (32, 32, 1)  # Example input shape with a channel dimension\n",
    "\n",
    "# Train the model\n",
    "#history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f23ff4c85c9b2baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_data(train_data, num_pairs):\n",
    "#     cleaned_data = []\n",
    "#     for data in train_data:\n",
    "#         try:\n",
    "#             x_gen_train = data[0]\n",
    "#             y_final_train = data[1]\n",
    "#             z_output = data[2]\n",
    "# \n",
    "#             for i in range(num_pairs * 2):\n",
    "#                 # print(x_gen_train[i].shape)\n",
    "#                 if x_gen_train[i].shape != (32, 32):\n",
    "#                     raise ValueError(f\"Unexpected shape for x_gen_train[{i}]: {x_gen_train[i].shape}\")\n",
    "# \n",
    "#             #print(y_final_train.shape)\n",
    "#             if y_final_train.shape != (32, 32):\n",
    "#                 raise ValueError(f\"Unexpected shape for y_final_train: {y_final_train.shape}\")\n",
    "# \n",
    "#             #print(z_output.shape)\n",
    "#             if z_output.shape != (32, 32):\n",
    "#                 raise ValueError(f\"Unexpected shape for z_output: {z_output.shape}\")\n",
    "# \n",
    "#             cleaned_data.append(data)\n",
    "# \n",
    "#         except ValueError as e:\n",
    "#             print(f\"Skipping due to error: {e}\")\n",
    "#             continue\n",
    "# \n",
    "#     if not cleaned_data:\n",
    "#         raise ValueError(\"No valid data entries found after cleaning.\")\n",
    "# \n",
    "#     return cleaned_data\n",
    "# \n",
    "# cleaned_train_data = clean_data(train_data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8ed7463e1207d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7fc26f75ba6edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, train_data, num_pairs, batch_size=32, shuffle=True):\n",
    "        self.train_data = train_data\n",
    "        self.num_pairs = num_pairs\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.train_data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_data = [self.train_data[k] for k in indices]\n",
    "        return self.__data_generation(batch_data)\n",
    "\n",
    "    def __data_generation(self, batch_data):\n",
    "        _data = batch_data[0]\n",
    "        x_gen_train = _data[0]\n",
    "        y_final_train = _data[1]\n",
    "        z_output = _data[2]\n",
    "\n",
    "        _x_train = [[np.expand_dims(x_gen_train[i], axis=-1) for i in range(self.num_pairs * 2)], np.expand_dims(y_final_train, axis=-1)]\n",
    "        _y_train = np.expand_dims(z_output, axis=-1)\n",
    "        return x_train, y_train\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.train_data))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "num_pairs = 5\n",
    "batch_size = 1\n",
    "# dummy_train_data = [(\n",
    "#     [np.random.rand(32, 32, 1) for _ in range(num_pairs * 2)],\n",
    "#     np.random.rand(32, 32, 1),\n",
    "#     np.random.rand(32, 32, 1)\n",
    "# ) for _ in range(10)]  # Use a smaller dataset for debugging\n",
    "\n",
    "# train_generator = DataGenerator(train_data, num_pairs, batch_size)\n",
    "# eval_generator = DataGenerator(eval_data, num_pairs, batch_size)\n",
    "# \n",
    "# model = create_transformer_model(input_shape, num_pairs)\n",
    "# model.summary()\n",
    "\n",
    "# # Train the model using the data generator\n",
    "# model.fit(train_generator, epochs=100, batch_size=batch_size, validation_data=eval_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c48e5eafdb4c68bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:13.372694Z",
     "start_time": "2024-06-15T22:27:12.786541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, None, 32, 3  0           []                               \n",
      "                                2, 1)]                                                            \n",
      "                                                                                                  \n",
      " process_pairs_layer (ProcessPa  (None, None, 1)     3205        ['input_4[0][0]']                \n",
      " irsLayer)                                                                                        \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 32, 32, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, None, 1)     2           ['process_pairs_layer[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1024, 1)      0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, None, 1)     2           ['layer_normalization_18[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 1024, 0)     0           ['reshape_3[0][0]']              \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, None, 1)     1793        ['layer_normalization_19[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 1024, 0)     0           ['tf.__operators__.add_2[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, None, 1)      0           ['multi_head_attention_8[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 1024, 0)     768         ['layer_normalization_23[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, None, 1)      0           ['dropout_16[0][0]',             \n",
      "                                                                  'process_pairs_layer[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 1024, 0)      0           ['multi_head_attention_10[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, None, 1)     2           ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 1024, 0)      0           ['dropout_20[0][0]',             \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, None, 128)    256         ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 1024, 0)     0           ['add_20[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, None, 128)    0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1024, 128)    128         ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, None, 1)      129         ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 1024, 128)    0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, None, 1)      0           ['dense_18[0][0]',               \n",
      "                                                                  'process_pairs_layer[0][0]']    \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 1024, 1)      129         ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, None, 1)     2           ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 1024, 1)      0           ['dense_22[0][0]',               \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, None, 1)     1793        ['layer_normalization_21[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 1024, 1)     2           ['add_21[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, None, 1)      0           ['multi_head_attention_9[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 1024, 1)     1793        ['layer_normalization_25[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, None, 1)      0           ['dropout_18[0][0]',             \n",
      "                                                                  'process_pairs_layer[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 1024, 1)      0           ['multi_head_attention_11[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, None, 1)     2           ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 1024, 1)      0           ['dropout_22[0][0]',             \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, None, 128)    256         ['layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 1024, 1)     2           ['add_22[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, None, 128)    0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1024, 128)    256         ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, None, 1)      129         ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 1024, 128)    0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, None, 1)      0           ['dense_20[0][0]',               \n",
      "                                                                  'process_pairs_layer[0][0]']    \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 1024, 1)      129         ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 1024, 1)      0           ['dense_24[0][0]',               \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_2 (TFOpLamb  (3,)                0           ['add_19[0][0]']                 \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1024)         0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  ()                  0           ['tf.compat.v1.shape_2[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_3 (TFOpLamb  (3,)                0           ['add_19[0][0]']                 \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, None)         0           ['reshape_4[0][0]',              \n",
      "                                                                  'tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  ()                  0           ['tf.compat.v1.shape_3[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, None, 1024)   0           ['lambda_6[0][0]',               \n",
      "                                                                  'tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)              (None, None, 1)      0           ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)              (None, None, 1024)   0           ['lambda_7[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, None, 1025)   0           ['lambda_8[0][0]',               \n",
      "                                                                  'lambda_9[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, None, 1025)  2050        ['concatenate_2[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, None, 1025)  2050        ['layer_normalization_27[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, None, 1025)  1051393     ['layer_normalization_28[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, None, 1025)   0           ['multi_head_attention_12[0][0]']\n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, None, 1025)   0           ['dropout_24[0][0]',             \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, None, 1025)  2050        ['add_24[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, None, 128)    131328      ['layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, None, 128)    0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, None, 1)      129         ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, None, 1025)   0           ['dense_26[0][0]',               \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, None, 1025)  2050        ['add_25[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, None, 1025)  1051393     ['layer_normalization_30[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, None, 1025)   0           ['multi_head_attention_13[0][0]']\n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, None, 1025)   0           ['dropout_26[0][0]',             \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, None, 1025)  2050        ['add_26[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, None, 128)    131328      ['layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, None, 128)    0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, None, 1)      129         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, None, 1025)   0           ['dense_28[0][0]',               \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, None, 1024)   1050624     ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)             (None, 32, 32, 1)    0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 32, 32, 32)   320         ['lambda_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 32, 32, 32)   9248        ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 32, 32, 1)    289         ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,447,209\n",
      "Trainable params: 3,447,209\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "class ProcessPairsLayer(layers.Layer):\n",
    "    def __init__(self, input_shape, pos_encoding, **kwargs):\n",
    "        super(ProcessPairsLayer, self).__init__(**kwargs)\n",
    "        self.input_shape_ = input_shape\n",
    "        self.pos_encoding = pos_encoding\n",
    "        self.head_size = 64\n",
    "        self.num_heads = 4\n",
    "        self.ff_dim = 128\n",
    "        self.dropout = 0.1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mha_layers = [layers.MultiHeadAttention(key_dim=self.head_size, num_heads=self.num_heads, dropout=self.dropout) for _ in range(2)]\n",
    "        self.ffn_layers = [self.build_ffn() for _ in range(2)]\n",
    "        super(ProcessPairsLayer, self).build(input_shape)\n",
    "\n",
    "    def build_ffn(self):\n",
    "        return tf.keras.Sequential([\n",
    "            layers.LayerNormalization(epsilon=1e-6),\n",
    "            layers.Dense(self.ff_dim, activation=tf.nn.gelu),\n",
    "            layers.Dropout(self.dropout),\n",
    "            layers.Dense(self.input_shape_[2])\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        num_pairs = tf.shape(inputs)[1]\n",
    "\n",
    "        reshaped_inputs = tf.reshape(inputs, (batch_size * num_pairs, self.input_shape_[0] * self.input_shape_[1], self.input_shape_[2]))\n",
    "        x = reshaped_inputs + self.pos_encoding\n",
    "\n",
    "        for mha_layer, ffn_layer in zip(self.mha_layers, self.ffn_layers):\n",
    "            x = mha_layer(x, x)\n",
    "            x = layers.Dropout(self.dropout)(x)\n",
    "            x = layers.Add()([x, reshaped_inputs])\n",
    "            x = ffn_layer(x)\n",
    "            x = layers.Add()([x, reshaped_inputs])\n",
    "\n",
    "        x = tf.reshape(x, (batch_size, num_pairs * self.input_shape_[0] * self.input_shape_[1], self.input_shape_[2]))\n",
    "        return x\n",
    "\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth // 2\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth\n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
    "    pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def create_transformer_model(input_shape):\n",
    "    pos_encoding = positional_encoding(input_shape[0] * input_shape[1], input_shape[2])\n",
    "\n",
    "    input_layer = Input(shape=(None, input_shape[0], input_shape[1], input_shape[2]))\n",
    "    processed_pairs = ProcessPairsLayer(input_shape, pos_encoding)(input_layer)\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(processed_pairs)\n",
    "    for _ in range(2):\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.MultiHeadAttention(key_dim=64, num_heads=4, dropout=0.1)(x, x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.Add()([x, processed_pairs])\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.Dense(128, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.Dense(input_shape[2])(x)\n",
    "        x = layers.Add()([x, processed_pairs])\n",
    "\n",
    "    final_input = Input(shape=input_shape)\n",
    "    flattened_final_input = layers.Reshape((input_shape[0] * input_shape[1], input_shape[2]))(final_input)\n",
    "    x_final = flattened_final_input + pos_encoding\n",
    "\n",
    "    for _ in range(2):\n",
    "        x_final = layers.LayerNormalization(epsilon=1e-6)(x_final)\n",
    "        x_final = layers.MultiHeadAttention(key_dim=64, num_heads=4, dropout=0.1)(x_final, x_final)\n",
    "        x_final = layers.Dropout(0.1)(x_final)\n",
    "        x_final = layers.Add()([x_final, flattened_final_input])\n",
    "        x_final = layers.LayerNormalization(epsilon=1e-6)(x_final)\n",
    "        x_final = layers.Dense(128, activation=tf.nn.gelu)(x_final)\n",
    "        x_final = layers.Dropout(0.1)(x_final)\n",
    "        x_final = layers.Dense(input_shape[2])(x_final)\n",
    "        x_final = layers.Add()([x_final, flattened_final_input])\n",
    "\n",
    "    flattened_x_final = layers.Reshape((-1,))(x_final)\n",
    "\n",
    "    def repeat_vector(args):\n",
    "        x, rep = args\n",
    "        return tf.repeat(x, repeats=rep, axis=1)\n",
    "\n",
    "    expanded_final_input = layers.Lambda(repeat_vector)([flattened_x_final, tf.shape(x)[1]])\n",
    "\n",
    "    def reshape_combined(args):\n",
    "        x, combined_shape = args\n",
    "        return tf.reshape(x, (-1, combined_shape, input_shape[0] * input_shape[1] * input_shape[2]))\n",
    "\n",
    "    expanded_final_input = layers.Lambda(reshape_combined)([expanded_final_input, tf.shape(x)[1]])\n",
    "\n",
    "    def flatten_combined_pairs(x):\n",
    "        shape = tf.shape(x)\n",
    "        return tf.reshape(x, (-1, shape[1], shape[2]))\n",
    "\n",
    "    combined_pairs_flat = layers.Lambda(flatten_combined_pairs)(x)\n",
    "    expanded_final_input_flat = layers.Lambda(flatten_combined_pairs)(expanded_final_input)\n",
    "\n",
    "    x_combined = layers.Concatenate(axis=-1)([combined_pairs_flat, expanded_final_input_flat])\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x_combined)\n",
    "    for _ in range(2):\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.MultiHeadAttention(key_dim=64, num_heads=4, dropout=0.1)(x, x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.Add()([x, x_combined])\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.Dense(128, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.Dense(input_shape[2])(x)\n",
    "        x = layers.Add()([x, x_combined])\n",
    "\n",
    "    x = layers.Dense(input_shape[0] * input_shape[1] * input_shape[2])(x)\n",
    "    def dynamic_reshape(tensor, shape):\n",
    "        return tf.reshape(tensor, shape)\n",
    "\n",
    "    output_shape = (-1, input_shape[0], input_shape[1], input_shape[2])\n",
    "    x = layers.Lambda(dynamic_reshape, arguments={'shape': output_shape})(x)\n",
    "\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(input_shape[2], 3, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = models.Model(inputs=[input_layer, final_input], outputs=x)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = (32, 32, 1)\n",
    "model = create_transformer_model(input_shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a72dcd14edba8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, train_data, batch_size=32, shuffle=True):\n",
    "        self.train_data = train_data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.train_data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_data = [self.train_data[k] for k in indices]\n",
    "        x, y = self.__data_generation(batch_data)\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.train_data))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, batch_data):\n",
    "        x_inputs = []\n",
    "        final_inputs = []\n",
    "        y_train_batch = []\n",
    "\n",
    "        for data in batch_data:\n",
    "            input_output_pairs = data[0]\n",
    "            final_input = data[1]\n",
    "            attended_output = data[2]\n",
    "\n",
    "            # Ensure input-output pairs are correctly shaped\n",
    "            pairs = np.stack(input_output_pairs, axis=0)\n",
    "            x_inputs.append(pairs)\n",
    "            final_inputs.append(final_input)\n",
    "            y_train_batch.append(attended_output)\n",
    "\n",
    "        x_inputs = np.stack(x_inputs)\n",
    "        final_inputs = np.stack(final_inputs)\n",
    "        y_train_batch = np.stack(y_train_batch)\n",
    "\n",
    "        return [x_inputs, final_inputs], y_train_batch\n",
    "    \n",
    "    \n",
    "#train_generator = DataGenerator(train_data)\n",
    "#model.fit(train_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7c292ef9874f3cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:27:17.924345Z",
     "start_time": "2024-06-15T22:27:17.908868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "def prepare_prediction_input(pairs, final_input):\n",
    "    \"\"\"\n",
    "    Prepare the input for prediction by stacking the input-output pairs\n",
    "    and the final input matrix.\n",
    "\n",
    "    :param pairs: List of input-output pairs (e.g., 8 matrices for 4 pairs).\n",
    "    :param final_input: The final input matrix to complete.\n",
    "    :return: Tuple of (stacked input pairs, final input matrix).\n",
    "    \"\"\"\n",
    "    pairs_tensor = np.stack(pairs, axis=0)\n",
    "    pairs_tensor = np.expand_dims(pairs_tensor, axis=0)  # Add batch dimension\n",
    "    final_input_tensor = np.expand_dims(final_input, axis=0)  # Add batch dimension\n",
    "\n",
    "    return pairs_tensor, final_input_tensor\n",
    "\n",
    "\n",
    "overfit_test = prepare_prediction_input(train_data[0][0], train_data[0][1])\n",
    "overfit_output = np.expand_dims(train_data[0][2], 0)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            physical_devices[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10240)]\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# model.fit(overfit_test, overfit_output, epochs=10)\n",
    "\n",
    "# Example input data for prediction\n",
    "# input_pairs = [np.random.rand(32, 32, 1) for _ in range(8)]  # 4 pairs = 8 matrices\n",
    "# final_input_matrix = np.random.rand(32, 32, 1)\n",
    "# \n",
    "# # Prepare the prediction input\n",
    "# x_input, final_input = prepare_prediction_input(input_pairs, final_input_matrix)\n",
    "# \n",
    "# # Perform prediction\n",
    "# # predicted_output = model.predict([x_input, final_input])\n",
    "# \n",
    "# output_desired = np.random.rand(32, 32, 1)\n",
    "# predicted_output = model.fit([x_input, final_input], np.expand_dims(output_desired, axis=0), epochs=10)\n",
    "# final_output_matrix = predicted_output[0, :, :, 0]\n",
    "# # Display the predicted output\n",
    "# display_output(final_output_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "# \n",
    "# for i in range(0, len(train_data)):\n",
    "#     # test_inputs = train_data[i][0].copy()\n",
    "#     # final_input = train_data[i][1].copy()\n",
    "#     # attended_output = train_data[i][2].copy()\n",
    "#     # \n",
    "#     # # for j in range(0, len(test_inputs)):\n",
    "#     # #     test_inputs[j] = np.expand_dims(test_inputs[j], axis=0)\n",
    "#     # #     display_output(test_inputs[j])\n",
    "#     #     #print(test_inputs[j].shape)\n",
    "#     # \n",
    "#     # pairs = np.stack(test_inputs, axis=0)\n",
    "#     \n",
    "#     def prepare_prediction_input(pairs, final_input):\n",
    "#         pairs_tensor = np.stack(pairs, axis=0)\n",
    "#         pairs_tensor = np.expand_dims(pairs_tensor, axis=0)\n",
    "#         final_input_tensor = np.expand_dims(final_input, axis=0)\n",
    "#         return pairs_tensor, final_input_tensor\n",
    "# \n",
    "#     # Example input data for prediction\n",
    "#     input_pairs = [np.random.rand(32, 32, 1) for _ in range(8)]  # 4 pairs = 8 matrices\n",
    "#     final_input_matrix = np.random.rand(32, 32, 1)\n",
    "#     \n",
    "#     # Prepare the prediction input\n",
    "#     x_input, final_input = prepare_prediction_input(input_pairs, final_input_matrix)\n",
    "#     \n",
    "#     # Perform prediction\n",
    "#     predicted_output = model.predict([x_input, final_input])\n",
    "# \n",
    "#     # x_train = [[test_inputs[i] for i in range(num_pairs * 2)], np.expand_dims(final_input, axis=0)]\n",
    "#     # x_train = [*test_inputs, np.expand_dims(final_input, axis=0)]\n",
    "#     ## we create a stack of the input pairs\n",
    "#     \n",
    "#     #print(len(x_train))\n",
    "#     # \n",
    "#     #y_train = np.expand_dims(attended_output, axis=0)\n",
    "#     # print(y_train.shape)\n",
    "#     # ## BEFORE\n",
    "#     # final_output = model.predict(x_train)\n",
    "#     # final_output_matrix = final_output[0, :, :, 0]\n",
    "#     # display_output(final_input, final_output_matrix)  # This will print the 32x32 matrix\n",
    "#     # \n",
    "#     #model.fit(x_train, y_train, epochs=100)\n",
    "# \n",
    "# #    final_output_matrix = final_output[0, :, :, 0]\n",
    "# \n",
    "# #    display_output(final_input, final_output_matrix)  # This will print the 32x32 matrix\n",
    "# #    display_output(final_input, attended_output)  # This will print the 32x32 matrix\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0cf41b65b73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = model.predict(x_train)\n",
    "final_output_matrix = final_output[0, :, :, 0]\n",
    "\n",
    "print(final_output_matrix.shape)  # Should print (32, 32)\n",
    "display_output(final_output_matrix, final_output_matrix)  # This will print the 32x32 matrix\n",
    "display_output(test_inputs[0], final_output_matrix)  # This will print the 32x32 matrix\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3913206424ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training data\n",
    "x_train = np.random.rand(100, 32, 32, 1).astype(np.float32)  # 100 samples with a channel dimension\n",
    "y_train = np.random.randint(0, 10, size=(100,)).astype(np.int32)  # 100 labels\n",
    "\n",
    "# Example validation data\n",
    "x_val = np.random.rand(20, 32, 32, 1).astype(np.float32)  # 20 samples with a channel dimension\n",
    "y_val = np.random.randint(0, 10, size=(20,)).astype(np.int32)  # 20 labels\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199326677f7219d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "!rm -rf ./logs/fit\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    # enabling histogram will crash the learninig in non-eager mode\n",
    "    histogram_freq=1, # every epoch\n",
    "    write_images=True, # visualize model weights in image form\n",
    "    update_freq='epoch', # this can be 'epoch' to make training faster (less logs)\n",
    ")\n",
    "\n",
    "%tensorboard --logdir logs/fit\n",
    "model.fit(x=train_data, epochs=50, validation_data=eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc5d75a44ddb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d179bd0b35f6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "z_pred = model.predict(train_data.take(1))\n",
    "print(z_pred)\n",
    "def display_output(output_1, output_2):\n",
    "    output_1 = output_1.reshape(32,32)\n",
    "    output_2 = output_2.reshape(32,32)\n",
    "    output_1 = denormalize_data(output_1)\n",
    "    output_2 = denormalize_data(output_2)\n",
    "    plot_grid(output_1, output_2)\n",
    "\n",
    "\n",
    "#display_output(train_data.take(1).as_numpy_iterator().next()[0]['c_input'], train_data.take(1).as_numpy_iterator().next()[0]['c_input'])\n",
    "display_output(train_data.take(1).as_numpy_iterator().next()[0]['c_input'], z_pred.reshape(32,32))\n",
    "\n",
    "attended_output = train_data.take(1).as_numpy_iterator().next()[1].reshape(32,32)\n",
    "display_output(train_data.take(1).as_numpy_iterator().next()[0]['c_input'], attended_output)\n",
    "#display_output(z_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189e398943cd4c1",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "def create_padded_model(max_pairs, max_shape=(32, 32)):\n",
    "    inputs = []\n",
    "    for i in range(max_pairs):\n",
    "        input_a = Input(shape=max_shape, name=f'input_a_{i+1}')\n",
    "        input_b = Input(shape=max_shape, name=f'input_b_{i+1}')\n",
    "        inputs.append(input_a)\n",
    "        inputs.append(input_b)\n",
    "\n",
    "    # Flatten and concatenate all inputs\n",
    "    flattened_inputs = [Flatten()(input_tensor) for input_tensor in inputs]\n",
    "    concatenated = Concatenate()(flattened_inputs)\n",
    "\n",
    "    # Define the rest of the model\n",
    "    x = Dense(256, activation='relu')(concatenated)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_padded_model(max_pairs=5, max_shape=(32, 32))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3795a999ddda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a data generator for training and validation data\n",
    "batch_size = 32\n",
    "train_generator = DataGenerator(train_data, batch_size=batch_size, max_pairs=5, max_shape=(32, 32))\n",
    "val_generator = DataGenerator(test_data, batch_size=batch_size, max_pairs=5, max_shape=(32, 32))\n",
    "\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, steps_per_epoch=len(train_data)//batch_size, validation_data=val_generator, validation_steps=len(val_data)//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687c174a3b669f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss = model.evaluate(test_generator)\n",
    "print('Test Loss:', test_loss)\n",
    "\n",
    "# Visualize a few test samples and their predictions\n",
    "def plot_predictions(model, X, y, num_samples=1):\n",
    "    predictions = model.predict(X[:num_samples])\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(10, 10))\n",
    "    for i in range(num_samples):\n",
    "        axes[i, 0].imshow(X[i].squeeze(), cmap='gray')\n",
    "        axes[i, 0].set_title('Input')\n",
    "        axes[i, 1].imshow(y[i].squeeze(), cmap='gray')\n",
    "        axes[i, 1].set_title('True Output')\n",
    "        axes[i, 2].imshow(predictions[i].squeeze(), cmap='gray')\n",
    "        axes[i, 2].set_title('Predicted Output')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot predictions (using a small subset of the test data)\n",
    "X_test_subset = np.array(X_test[:5])\n",
    "y_test_subset = np.array(y_test[:5])\n",
    "plot_predictions(model, X_test_subset, y_test_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bb340d4f62e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
