{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a480c306385e473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.444632Z",
     "start_time": "2024-06-16T09:29:25.435643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c011106ddd21c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.480615Z",
     "start_time": "2024-06-16T09:29:25.477622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0f2a117ca84fc97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.501068Z",
     "start_time": "2024-06-16T09:29:25.495008Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# RGB\n",
    "colors_rgb = {\n",
    "    0: (0x00, 0x00, 0x00),\n",
    "    1: (0x00, 0x74, 0xD9),\n",
    "    2: (0xFF, 0x41, 0x36),\n",
    "    3: (0x2E, 0xCC, 0x40),\n",
    "    4: (0xFF, 0xDC, 0x00),\n",
    "    5: (0xA0, 0xA0, 0xA0),\n",
    "    6: (0xF0, 0x12, 0xBE),\n",
    "    7: (0xFF, 0x85, 0x1B),\n",
    "    8: (0x7F, 0xDB, 0xFF),\n",
    "    9: (0x87, 0x0C, 0x25),\n",
    "}\n",
    "\n",
    "_float_colors = [tuple(c / 255 for c in col) for col in colors_rgb.values()]\n",
    "arc_cmap = ListedColormap(_float_colors)\n",
    "\n",
    "class ArcColors:\n",
    "    BLACK = 0\n",
    "    BLUE = 1\n",
    "    RED = 2\n",
    "    GREEN = 3\n",
    "    YELLOW = 4\n",
    "    GREY = 5\n",
    "    FUCHSIA = 6\n",
    "    ORANGE = 7\n",
    "    TEAL = 8\n",
    "    BROWN = 9\n",
    "\n",
    "def plot_grid(grid1: np.ndarray, grid2: np.ndarray = None):\n",
    "    \n",
    "    if grid2 is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.pcolormesh(\n",
    "            grid1,\n",
    "            cmap=arc_cmap,\n",
    "            rasterized=True,\n",
    "            vmin=0,\n",
    "            vmax=9,\n",
    "        )\n",
    "        ax.set_xticks(np.arange(0, grid1.shape[1], 1))\n",
    "        ax.set_yticks(np.arange(0, grid1.shape[0], 1))\n",
    "        ax.grid()\n",
    "        ax.set_aspect(1)\n",
    "        ax.invert_yaxis()\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "    axs[0].pcolormesh(\n",
    "        grid1,\n",
    "        cmap=arc_cmap,\n",
    "        rasterized=True,\n",
    "        vmin=0,\n",
    "        vmax=9,\n",
    "    )\n",
    "    axs[0].set_xticks(np.arange(0, grid1.shape[1], 1))\n",
    "    axs[0].set_yticks(np.arange(0, grid1.shape[0], 1))\n",
    "    axs[0].grid()\n",
    "    axs[0].set_aspect(1)\n",
    "    axs[0].invert_yaxis()\n",
    "\n",
    "    axs[1].pcolormesh(\n",
    "        grid2,\n",
    "        cmap=arc_cmap,\n",
    "        rasterized=True,\n",
    "        vmin=0,\n",
    "        vmax=9,\n",
    "    )\n",
    "    axs[1].set_xticks(np.arange(0, grid2.shape[1], 1))\n",
    "    axs[1].set_yticks(np.arange(0, grid2.shape[0], 1))\n",
    "    axs[1].grid()\n",
    "    axs[1].set_aspect(1)\n",
    "    axs[1].invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002e93852e21530",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2fdf457cb89d81c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.505586Z",
     "start_time": "2024-06-16T09:29:25.502073Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Load the data from the data/train directory containing the json files\n",
    "# files are named {random_number}.json so you need to list all the files in the directory and then load the data from each file\n",
    "training_data_dir = \"../data/training\"\n",
    "evaluating_data_dir = \"../data/evaluation\"\n",
    "\n",
    "# List of JSON file paths\n",
    "# training_file_paths = [os.path.join(training_data_dir, f) for f in os.listdir(training_data_dir)]\n",
    "# evaluating_file_paths = [os.path.join(evaluating_data_dir, f) for f in os.listdir(evaluating_data_dir)]\n",
    "training_file_paths = [os.path.join(training_data_dir, \"3c9b0459.json\")]\n",
    "evaluating_file_paths = [os.path.join(training_data_dir, \"3c9b0459.json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89d657ca853de629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.524117Z",
     "start_time": "2024-06-16T09:29:25.520143Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Function to load data from multiple files\n",
    "\n",
    "def load_data(file_paths):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for file_path in file_paths:\n",
    "        rules_input = []\n",
    "        test_input = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for item in data['train']:\n",
    "                rules_input.append([\n",
    "                    np.array(item['input'], dtype=np.int64),\n",
    "                    np.array(item['output'], dtype=np.int64)\n",
    "                ])\n",
    "            for item in data['test']:\n",
    "                test_input.append([\n",
    "                    np.array(item['input'], dtype=np.int64),\n",
    "                    np.array(item['output'], dtype=np.int64)\n",
    "                ])\n",
    "        train_data.append(rules_input)\n",
    "        test_data.append(test_input)\n",
    "    return train_data, test_data\n",
    "\n",
    "# Load data from multiple files\n",
    "training_train_data, training_test_data = load_data(training_file_paths)\n",
    "evaluating_train_data, evaluating_test_data = load_data(evaluating_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a708f14a6cf007",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "We setup the data to be fed into the model into a 32x32 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8e6ac129aaa674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.530164Z",
     "start_time": "2024-06-16T09:29:25.525132Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    return data / 9.0\n",
    "\n",
    "def denormalize_data(data):\n",
    "    return data * 9.0\n",
    "\n",
    "def expand_squared_matrix(matrix, size):\n",
    "    max_size = size\n",
    "    current_size = matrix.shape[0]\n",
    "    if current_size == max_size:\n",
    "        return normalize_data(matrix)\n",
    "    \n",
    "    ratio = max_size / current_size\n",
    "    floor_ratio = int(np.floor(ratio))\n",
    "    \n",
    "    if floor_ratio * current_size == max_size:\n",
    "        return normalize_data(matrix.repeat(floor_ratio, axis=0).repeat(floor_ratio, axis=1))\n",
    "    \n",
    "    resized_matrix = matrix.repeat(floor_ratio, axis=0).repeat(floor_ratio, axis=1)\n",
    "    pad_size = max_size - resized_matrix.shape[0]\n",
    "    \n",
    "    padded_matrix = np.full((max_size, max_size), 0)\n",
    "    padded_matrix[pad_size//2:pad_size//2+resized_matrix.shape[0], pad_size//2:pad_size//2+resized_matrix.shape[1]] = resized_matrix\n",
    "    \n",
    "    return normalize_data(padded_matrix)\n",
    "\n",
    "def expand_rectangular_matrix(matrix, size):\n",
    "    max_size = 32\n",
    "    current_size = matrix.shape[0]\n",
    "    current_width = matrix.shape[1]\n",
    "    if current_size == max_size and current_width == max_size:\n",
    "        return normalize_data(matrix)\n",
    "    ratio = max_size // current_size\n",
    "    ratio_width = max_size // current_width\n",
    "    divisible = ratio * current_size == max_size and ratio_width * current_width == max_size\n",
    "    if divisible is True:\n",
    "       return normalize_data(matrix.repeat(ratio, axis=0).repeat(ratio_width, axis=1))\n",
    "\n",
    "    ## if the size is not divisible by 32\n",
    "    ## we need to add padding and center the reiszed image\n",
    "    floor_ratio = np.floor(ratio)\n",
    "    floor_ratio_width = np.floor(ratio_width)\n",
    "    resized_matrix = matrix.repeat(floor_ratio, axis=0).repeat(floor_ratio_width, axis=1)\n",
    "    pad_size = max_size - resized_matrix.shape[0]\n",
    "    pad_size_width = max_size - resized_matrix.shape[1]\n",
    "    padded_matrix = np.full(size, 0)\n",
    "    padded_matrix[pad_size//2:pad_size//2+resized_matrix.shape[0], pad_size_width//2:pad_size_width//2+resized_matrix.shape[1]] = resized_matrix\n",
    "    return normalize_data(padded_matrix)\n",
    "\n",
    "def expand_matrix(matrix, size):\n",
    "    if matrix.shape[0] == matrix.shape[1]:\n",
    "        return expand_squared_matrix(matrix, size[0])\n",
    "    return expand_rectangular_matrix(matrix, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2ecd6436dda594b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.678598Z",
     "start_time": "2024-06-16T09:29:25.531093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test expand_matrix\n",
    "plot_grid(denormalize_data(expand_matrix(training_train_data[0][0][0], (3, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e8cb31d1d187f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.681526Z",
     "start_time": "2024-06-16T09:29:25.679596Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_SHAPE = (3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e5811b71d2c3b",
   "metadata": {},
   "source": [
    "### Data preparation for the transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa99c80db85401e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.687109Z",
     "start_time": "2024-06-16T09:29:25.682235Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_data_for_transformer(train, test, max_shape=MAX_SHAPE):\n",
    "    pairs = []\n",
    "    for i, element in enumerate(train):\n",
    "        expanded_0 = expand_matrix(element[0], max_shape)\n",
    "        expanded_1 = expand_matrix(element[1], max_shape)\n",
    "        pairs.append(expanded_0)\n",
    "        pairs.append(expanded_1)\n",
    "\n",
    "\n",
    "    final_test = expand_matrix(test[0][0], max_shape)\n",
    "    attended_output = expand_matrix(test[0][1], max_shape)\n",
    "    return pairs, final_test, attended_output\n",
    "\n",
    "def extract_batch (data, test):\n",
    "    batches = []\n",
    "    for i in range(0, len(data)):\n",
    "        extracted = extract_data_for_transformer(data[i], test[i])\n",
    "        batches.append(extracted)\n",
    "        ### augment the data\n",
    "        for j in range(3):\n",
    "            rotated = [[np.rot90(x, j+1) for x in extracted[0]], np.rot90(extracted[1], j+1), np.rot90(extracted[2], j+1)]\n",
    "            batches.append(rotated)\n",
    "            batches.append([[np.flip(x, 0) for x in rotated[0]], np.flip(rotated[1], 0), np.flip(rotated[2], 0)])\n",
    "        batches.append([[np.flip(x, 1) for x in extracted[0]], np.flip(extracted[1], 1), np.flip(extracted[2], 1)])\n",
    "    return batches\n",
    "\n",
    "train_data = extract_batch(training_train_data[:1], training_test_data[:1])\n",
    "eval_data = extract_batch(evaluating_train_data[:1], evaluating_test_data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad7869e9884e01",
   "metadata": {},
   "source": [
    "### Layer to process pairs of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4685722bbc384ea9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.708171Z",
     "start_time": "2024-06-16T09:29:25.688755Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "class ProcessPairsLayer(layers.Layer):\n",
    "    def __init__(self, input_shape, pos_encoding, **kwargs):\n",
    "        super(ProcessPairsLayer, self).__init__(**kwargs)\n",
    "        self.input_shape_ = input_shape\n",
    "        self.pos_encoding = pos_encoding\n",
    "        self.head_size = 32 # 64 -> 32 to reduce the number of parameters\n",
    "        self.num_heads = 2 # 4 -> 2 to reduce the number of parameters \n",
    "        self.ff_dim = 64 # 128 -> 64 to reduce the number of parameters\n",
    "        self.dropout = 0.1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mha_layers = [layers.MultiHeadAttention(key_dim=self.head_size, num_heads=self.num_heads, dropout=self.dropout) for _ in range(2)]\n",
    "        self.ffn_layers = [self.build_ffn() for _ in range(2)]\n",
    "        super(ProcessPairsLayer, self).build(input_shape)\n",
    "\n",
    "    def build_ffn(self):\n",
    "        return tf.keras.Sequential([\n",
    "            layers.LayerNormalization(epsilon=1e-6),\n",
    "            layers.Dense(self.ff_dim, activation=tf.nn.gelu),\n",
    "            layers.Dropout(self.dropout),\n",
    "            layers.Dense(self.input_shape_[2])\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        num_pairs = tf.shape(inputs)[1]\n",
    "\n",
    "        reshaped_inputs = tf.reshape(inputs, (batch_size * num_pairs, self.input_shape_[0] * self.input_shape_[1], self.input_shape_[2]))\n",
    "        x = reshaped_inputs + self.pos_encoding\n",
    "\n",
    "        for mha_layer, ffn_layer in zip(self.mha_layers, self.ffn_layers):\n",
    "            x = mha_layer(x, x)\n",
    "            x = layers.Dropout(self.dropout)(x)\n",
    "            x = layers.Add()([x, reshaped_inputs])\n",
    "            x = ffn_layer(x)\n",
    "            x = layers.Add()([x, reshaped_inputs])\n",
    "\n",
    "        x = tf.reshape(x, (batch_size, num_pairs * self.input_shape_[0] * self.input_shape_[1], self.input_shape_[2]))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7295415da818dc0",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d22e39b42c628b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:25.711586Z",
     "start_time": "2024-06-16T09:29:25.709245Z"
    }
   },
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth // 2\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth\n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
    "    pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16effc4c465f2564",
   "metadata": {},
   "source": [
    "### Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5259b60a504b8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:26.678029Z",
     "start_time": "2024-06-16T09:29:25.712236Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None, 3, 3, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " process_pairs_layer (Proce  (None, None, 1)              965       ['input_1[0][0]']             \n",
      " ssPairsLayer)                                                                                    \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 3, 3, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, None, 1)              2         ['process_pairs_layer[0][0]'] \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 9, 1)                 0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, None, 1)              2         ['layer_normalization[0][0]'] \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 9, 0)                 0         ['reshape[0][0]']             \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, None, 1)              1793      ['layer_normalization_1[0][0]'\n",
      " iHeadAttention)                                                    , 'layer_normalization_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 9, 0)                 0         ['tf.__operators__.add[0][0]']\n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, None, 1)              0         ['multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, 9, 0)                 768       ['layer_normalization_5[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add (Add)                   (None, None, 1)              0         ['dropout[0][0]',             \n",
      "                                                                     'process_pairs_layer[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 9, 0)                 0         ['multi_head_attention_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, None, 1)              2         ['add[0][0]']                 \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 9, 0)                 0         ['dropout_4[0][0]',           \n",
      "                                                                     'reshape[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 128)            256       ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 9, 0)                 0         ['add_4[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, None, 128)            0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 9, 128)               128       ['layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, None, 1)              129       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 9, 128)               0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, None, 1)              0         ['dense_1[0][0]',             \n",
      "                                                                     'process_pairs_layer[0][0]'] \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 9, 1)                 129       ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, None, 1)              2         ['add_1[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 9, 1)                 0         ['dense_5[0][0]',             \n",
      "                                                                     'reshape[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, None, 1)              1793      ['layer_normalization_3[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 9, 1)                 2         ['add_5[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, None, 1)              0         ['multi_head_attention_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 9, 1)                 1793      ['layer_normalization_7[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, None, 1)              0         ['dropout_2[0][0]',           \n",
      "                                                                     'process_pairs_layer[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 9, 1)                 0         ['multi_head_attention_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, None, 1)              2         ['add_2[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 9, 1)                 0         ['dropout_6[0][0]',           \n",
      "                                                                     'reshape[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, None, 128)            256       ['layer_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (None, 9, 1)                 2         ['add_6[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, None, 128)            0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 9, 128)               256       ['layer_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, None, 1)              129       ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 9, 128)               0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, None, 1)              0         ['dense_3[0][0]',             \n",
      "                                                                     'process_pairs_layer[0][0]'] \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 9, 1)                 129       ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 9, 1)                 0         ['dense_7[0][0]',             \n",
      "                                                                     'reshape[0][0]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLa  (3,)                         0         ['add_3[0][0]']               \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 9)                    0         ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  ()                           0         ['tf.compat.v1.shape[0][0]']  \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOp  (3,)                         0         ['add_3[0][0]']               \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, None)                 0         ['reshape_1[0][0]',           \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_1[0][0]']\n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, None, 9)              0         ['lambda[0][0]',              \n",
      "                                                                     'tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)           (None, None, 1)              0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)           (None, None, 9)              0         ['lambda_1[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, None, 10)             0         ['lambda_2[0][0]',            \n",
      "                                                                     'lambda_3[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (None, None, 10)             20        ['concatenate[0][0]']         \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, None, 10)             20        ['layer_normalization_9[0][0]'\n",
      " yerNormalization)                                                  ]                             \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, None, 10)             11018     ['layer_normalization_10[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, None, 10)             0         ['multi_head_attention_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, None, 10)             0         ['dropout_8[0][0]',           \n",
      "                                                                     'concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, None, 10)             20        ['add_8[0][0]']               \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, None, 128)            1408      ['layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, None, 128)            0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, None, 1)              129       ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, None, 10)             0         ['dense_9[0][0]',             \n",
      "                                                                     'concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (None, None, 10)             20        ['add_9[0][0]']               \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, None, 10)             11018     ['layer_normalization_12[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, None, 10)             0         ['multi_head_attention_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, None, 10)             0         ['dropout_10[0][0]',          \n",
      "                                                                     'concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, None, 10)             20        ['add_10[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, None, 128)            1408      ['layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, None, 128)            0         ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, None, 1)              129       ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, None, 10)             0         ['dense_11[0][0]',            \n",
      "                                                                     'concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, None, 9)              99        ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)           (None, 3, 3, 1)              0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 3, 3, 16)             160       ['lambda_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 3, 3, 16)             2320      ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 1)              145       ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36472 (142.47 KB)\n",
      "Trainable params: 36472 (142.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    threshold = 0.1\n",
    "    diff = tf.abs(y_true - y_pred)\n",
    "    correct_predictions = tf.less(diff, threshold)\n",
    "    return tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "\n",
    "def create_transformer_model(input_shape):\n",
    "    pos_encoding = positional_encoding(input_shape[0] * input_shape[1], input_shape[2])\n",
    "\n",
    "    input_layer = Input(shape=(None, input_shape[0], input_shape[1], input_shape[2]))\n",
    "    processed_pairs = ProcessPairsLayer(input_shape, pos_encoding)(input_layer)\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(processed_pairs)\n",
    "    for _ in range(2):\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.MultiHeadAttention(key_dim=64, num_heads=4, dropout=0.1)(x, x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.Add()([x, processed_pairs])\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.Dense(128, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.Dense(input_shape[2])(x)\n",
    "        x = layers.Add()([x, processed_pairs])\n",
    "\n",
    "    final_input = Input(shape=input_shape)\n",
    "    flattened_final_input = layers.Reshape((input_shape[0] * input_shape[1], input_shape[2]))(final_input)\n",
    "    x_final = flattened_final_input + pos_encoding\n",
    "\n",
    "    for _ in range(2):\n",
    "        x_final = layers.LayerNormalization(epsilon=1e-6)(x_final)\n",
    "        x_final = layers.MultiHeadAttention(key_dim=64, num_heads=4, dropout=0.1)(x_final, x_final)\n",
    "        x_final = layers.Dropout(0.1)(x_final)\n",
    "        x_final = layers.Add()([x_final, flattened_final_input])\n",
    "        x_final = layers.LayerNormalization(epsilon=1e-6)(x_final)\n",
    "        x_final = layers.Dense(128, activation=tf.nn.gelu)(x_final)\n",
    "        x_final = layers.Dropout(0.1)(x_final)\n",
    "        x_final = layers.Dense(input_shape[2])(x_final)\n",
    "        x_final = layers.Add()([x_final, flattened_final_input])\n",
    "\n",
    "    flattened_x_final = layers.Reshape((-1,))(x_final)\n",
    "\n",
    "    def repeat_vector(args):\n",
    "        x, rep = args\n",
    "        return tf.repeat(x, repeats=rep, axis=1)\n",
    "\n",
    "    expanded_final_input = layers.Lambda(repeat_vector)([flattened_x_final, tf.shape(x)[1]])\n",
    "\n",
    "    def reshape_combined(args):\n",
    "        x, combined_shape = args\n",
    "        return tf.reshape(x, (-1, combined_shape, input_shape[0] * input_shape[1] * input_shape[2]))\n",
    "\n",
    "    expanded_final_input = layers.Lambda(reshape_combined)([expanded_final_input, tf.shape(x)[1]])\n",
    "\n",
    "    def flatten_combined_pairs(x):\n",
    "        shape = tf.shape(x)\n",
    "        return tf.reshape(x, (-1, shape[1], shape[2]))\n",
    "\n",
    "    combined_pairs_flat = layers.Lambda(flatten_combined_pairs)(x)\n",
    "    expanded_final_input_flat = layers.Lambda(flatten_combined_pairs)(expanded_final_input)\n",
    "\n",
    "    x_combined = layers.Concatenate(axis=-1)([combined_pairs_flat, expanded_final_input_flat])\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x_combined)\n",
    "    for _ in range(2):\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.MultiHeadAttention(key_dim=64, num_heads=4, dropout=0.1)(x, x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.Add()([x, x_combined])\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.Dense(128, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.Dense(input_shape[2])(x)\n",
    "        x = layers.Add()([x, x_combined])\n",
    "\n",
    "    x = layers.Dense(input_shape[0] * input_shape[1] * input_shape[2])(x)\n",
    "    def dynamic_reshape(tensor, shape):\n",
    "        return tf.reshape(tensor, shape)\n",
    "\n",
    "    output_shape = (-1, input_shape[0], input_shape[1], input_shape[2])\n",
    "    x = layers.Lambda(dynamic_reshape, arguments={'shape': output_shape})(x)\n",
    "\n",
    "    x = layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\")(x) # 32 -> 16 to reduce the number of parameters\n",
    "    x = layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\")(x) # 32 -> 16 to reduce the number of parameters\n",
    "    x = layers.Conv2D(input_shape[2], 3, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = models.Model(inputs=[input_layer, final_input], outputs=x)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[custom_accuracy])\n",
    "    return model\n",
    "\n",
    "input_shape = (3, 3, 1)\n",
    "model = create_transformer_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abae5f98e2fcfaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def prepare_prediction_input(pairs, final_input):\n",
    "    \"\"\"\n",
    "    Prepare the input for prediction by stacking the input-output pairs\n",
    "    and the final input matrix.\n",
    "\n",
    "    :param pairs: List of input-output pairs (e.g., 8 matrices for 4 pairs).\n",
    "    :param final_input: The final input matrix to complete.\n",
    "    :return: Tuple of (stacked input pairs, final input matrix).\n",
    "    \"\"\"\n",
    "    pairs_tensor = tf.stack(pairs, axis=0)\n",
    "    pairs_tensor = tf.expand_dims(pairs_tensor, axis=0)  # Add batch dimension\n",
    "    final_input_tensor = tf.expand_dims(final_input, axis=0)  # Add batch dimension\n",
    "    return pairs_tensor, final_input_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2070a2be1eb9dff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 11:29:26.721369: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#overfit_test = prepare_prediction_input(train_data[0][0], train_data[0][1])\n",
    "## cut the train_data[0][0] to 1 pairs\n",
    "cutted_pairs = train_data[0][0][:2]\n",
    "overfit_test = prepare_prediction_input(cutted_pairs, train_data[0][1])\n",
    "overfit_output = np.expand_dims(train_data[0][2], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c5e62fb48d70210",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:29:29.420502Z",
     "start_time": "2024-06-16T09:29:26.747055Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 11:29:27.120807: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.523352  ],\n",
       "         [0.48432517],\n",
       "         [0.47899544]],\n",
       "\n",
       "        [[0.49543628],\n",
       "         [0.4580811 ],\n",
       "         [0.4624604 ]],\n",
       "\n",
       "        [[0.49470523],\n",
       "         [0.46637708],\n",
       "         [0.4371475 ]]],\n",
       "\n",
       "\n",
       "       [[[0.523352  ],\n",
       "         [0.48432517],\n",
       "         [0.47899544]],\n",
       "\n",
       "        [[0.49543628],\n",
       "         [0.4580811 ],\n",
       "         [0.4624604 ]],\n",
       "\n",
       "        [[0.49470523],\n",
       "         [0.46637708],\n",
       "         [0.4371475 ]]],\n",
       "\n",
       "\n",
       "       [[[0.51909256],\n",
       "         [0.48755103],\n",
       "         [0.48295993]],\n",
       "\n",
       "        [[0.49643174],\n",
       "         [0.46590668],\n",
       "         [0.46939623]],\n",
       "\n",
       "        [[0.49548057],\n",
       "         [0.47305068],\n",
       "         [0.44899997]]],\n",
       "\n",
       "\n",
       "       [[[0.5250196 ],\n",
       "         [0.48682538],\n",
       "         [0.4791519 ]],\n",
       "\n",
       "        [[0.49637684],\n",
       "         [0.45688072],\n",
       "         [0.4608141 ]],\n",
       "\n",
       "        [[0.49236166],\n",
       "         [0.46872288],\n",
       "         [0.4375427 ]]],\n",
       "\n",
       "\n",
       "       [[[0.51909256],\n",
       "         [0.48755103],\n",
       "         [0.48295993]],\n",
       "\n",
       "        [[0.49643174],\n",
       "         [0.46590668],\n",
       "         [0.46939623]],\n",
       "\n",
       "        [[0.49548057],\n",
       "         [0.47305068],\n",
       "         [0.44899997]]],\n",
       "\n",
       "\n",
       "       [[[0.5250196 ],\n",
       "         [0.48682538],\n",
       "         [0.4791519 ]],\n",
       "\n",
       "        [[0.49637684],\n",
       "         [0.45688072],\n",
       "         [0.4608141 ]],\n",
       "\n",
       "        [[0.49236166],\n",
       "         [0.46872288],\n",
       "         [0.4375427 ]]],\n",
       "\n",
       "\n",
       "       [[[0.523352  ],\n",
       "         [0.48432517],\n",
       "         [0.47899544]],\n",
       "\n",
       "        [[0.49543628],\n",
       "         [0.4580811 ],\n",
       "         [0.4624604 ]],\n",
       "\n",
       "        [[0.49470523],\n",
       "         [0.46637708],\n",
       "         [0.4371475 ]]],\n",
       "\n",
       "\n",
       "       [[[0.5633832 ],\n",
       "         [0.48004887],\n",
       "         [0.4536166 ]],\n",
       "\n",
       "        [[0.49398127],\n",
       "         [0.40387484],\n",
       "         [0.4097471 ]],\n",
       "\n",
       "        [[0.4747809 ],\n",
       "         [0.4374721 ],\n",
       "         [0.366103  ]]],\n",
       "\n",
       "\n",
       "       [[[0.5193866 ],\n",
       "         [0.4844897 ],\n",
       "         [0.48148668]],\n",
       "\n",
       "        [[0.4954684 ],\n",
       "         [0.46433216],\n",
       "         [0.46816716]],\n",
       "\n",
       "        [[0.4967273 ],\n",
       "         [0.46803206],\n",
       "         [0.44424433]]],\n",
       "\n",
       "\n",
       "       [[[0.5193866 ],\n",
       "         [0.4844897 ],\n",
       "         [0.48148668]],\n",
       "\n",
       "        [[0.4954684 ],\n",
       "         [0.46433216],\n",
       "         [0.46816716]],\n",
       "\n",
       "        [[0.4967273 ],\n",
       "         [0.46803206],\n",
       "         [0.44424433]]],\n",
       "\n",
       "\n",
       "       [[[0.5605952 ],\n",
       "         [0.48429582],\n",
       "         [0.457774  ]],\n",
       "\n",
       "        [[0.49524042],\n",
       "         [0.41065577],\n",
       "         [0.4153634 ]],\n",
       "\n",
       "        [[0.47365987],\n",
       "         [0.44485492],\n",
       "         [0.3771002 ]]],\n",
       "\n",
       "\n",
       "       [[[0.5250196 ],\n",
       "         [0.48682538],\n",
       "         [0.4791519 ]],\n",
       "\n",
       "        [[0.49637684],\n",
       "         [0.45688072],\n",
       "         [0.4608141 ]],\n",
       "\n",
       "        [[0.49236166],\n",
       "         [0.46872288],\n",
       "         [0.4375427 ]]],\n",
       "\n",
       "\n",
       "       [[[0.5250196 ],\n",
       "         [0.48682538],\n",
       "         [0.4791519 ]],\n",
       "\n",
       "        [[0.49637684],\n",
       "         [0.45688072],\n",
       "         [0.4608141 ]],\n",
       "\n",
       "        [[0.49236166],\n",
       "         [0.46872288],\n",
       "         [0.4375427 ]]],\n",
       "\n",
       "\n",
       "       [[[0.51909256],\n",
       "         [0.48755103],\n",
       "         [0.48295993]],\n",
       "\n",
       "        [[0.49643174],\n",
       "         [0.46590668],\n",
       "         [0.46939623]],\n",
       "\n",
       "        [[0.49548057],\n",
       "         [0.47305068],\n",
       "         [0.44899997]]],\n",
       "\n",
       "\n",
       "       [[[0.523352  ],\n",
       "         [0.48432517],\n",
       "         [0.47899544]],\n",
       "\n",
       "        [[0.49543628],\n",
       "         [0.4580811 ],\n",
       "         [0.4624604 ]],\n",
       "\n",
       "        [[0.49470523],\n",
       "         [0.46637708],\n",
       "         [0.4371475 ]]],\n",
       "\n",
       "\n",
       "       [[[0.5193866 ],\n",
       "         [0.4844897 ],\n",
       "         [0.48148668]],\n",
       "\n",
       "        [[0.4954684 ],\n",
       "         [0.46433216],\n",
       "         [0.46816716]],\n",
       "\n",
       "        [[0.4967273 ],\n",
       "         [0.46803206],\n",
       "         [0.44424433]]],\n",
       "\n",
       "\n",
       "       [[[0.52398187],\n",
       "         [0.48269513],\n",
       "         [0.47799137]],\n",
       "\n",
       "        [[0.49477643],\n",
       "         [0.45634297],\n",
       "         [0.4611411 ]],\n",
       "\n",
       "        [[0.4951958 ],\n",
       "         [0.4637228 ],\n",
       "         [0.43390962]]],\n",
       "\n",
       "\n",
       "       [[[0.52398187],\n",
       "         [0.48269513],\n",
       "         [0.47799137]],\n",
       "\n",
       "        [[0.49477643],\n",
       "         [0.45634297],\n",
       "         [0.4611411 ]],\n",
       "\n",
       "        [[0.4951958 ],\n",
       "         [0.4637228 ],\n",
       "         [0.43390962]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(overfit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0636ed81c1f94",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-16T09:29:29.423183Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 11:29:30.962691: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.fit(overfit_test, overfit_output, epochs=1, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c92bb90db329419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_output(output_1, output_2=None):\n",
    "    output_1 = output_1.reshape(MAX_SHAPE[0], MAX_SHAPE[1])\n",
    "    output_1 = denormalize_data(output_1)\n",
    "    \n",
    "    if output_2 is None:\n",
    "        plot_grid(output_1)\n",
    "        return\n",
    "    output_2 = denormalize_data(output_2)\n",
    "    output_2 = output_2.reshape(MAX_SHAPE[0], MAX_SHAPE[1])\n",
    "    plot_grid(output_1, output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb235e3bfc891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(overfit_test)\n",
    "display_output(result[0, :, :, 0], overfit_output[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
